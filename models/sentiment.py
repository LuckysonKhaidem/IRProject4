# -*- coding: utf-8 -*-
"""Sentiment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-kkdEuInSjCzS7Y9uXxvxsvV0XqJTeLV
"""

from textblob import TextBlob
import json
#from google.colab import files
import matplotlib.pyplot as plt
#pip install googletrans
from googletrans import Translator
from pprint import pprint
import seaborn as sns
import pandas as pd
from nltk.tokenize import RegexpTokenizer
from nltk.corpus import stopwords
import nltk
nltk.download('stopwords')
from nltk.probability import FreqDist
import plotly.express as px
import mpld3
from mpld3 import plugins

class SentimentAnalyzer:
    
    def __init__(self,data):
        self.data=data
    
    def analyse_sentiment(self,tweets):
      for doc in tweets:
        analysis=TextBlob(doc['text_en'])
        if analysis.sentiment.polarity > 0:
            doc['sentiment']="Positive"
        elif analysis.sentiment.polarity == 0:
            doc['sentiment']="Neutral"
        else:
            doc['sentiment']="Negative"
      return tweets
  
    def translate_data(self,tweets):
        translator = Translator()
        for i in tweets:
          if(i['text_hi']!=None):
            translated=translator.translate(i['text_hi'])
            i['text_en']=translated.text
          if(i['text_pt']!=None):
            translated=translator.translate(i['text_pt'])
            i['text_en']=translated.text
        return tweets
    
    def remove_stopwords(self,tweets):
        stop_words_en = stopwords.words('english')
        return [[word for word in doc if word not in stop_words_en] for doc in tweets]
    
    def tokenize_tweets(self,tweets):
        tokenizer = RegexpTokenizer(r'\w+')
        tokenized_list_en = [tokenizer.tokenize(doc['text_en']) for doc in tweets]
        return tokenized_list_en
    
    def get_top10_words(self,tweets):
        word_list=[]
        for wrd_list in tweets:
          for wrd in wrd_list:
            word_list.append(wrd)
        fdist = FreqDist(word_list)
        fd = pd.DataFrame(fdist.most_common(10),columns = ["Word","Frequency"]).drop([0]).reindex()        
        return fd

    def generate_top10_word_plot(self,topwrds):
        fig, ax = plt.subplots()
        freq_plot=ax.bar(topwrds['Word'],topwrds['Frequency'])
        ax.set_title('Top 10 Frequent Word in Replies',size=20)
        plt.xticks(topwrds['Word'], rotation='vertical')
        #fig.suptitle('Sentiment Analysis of Tweet Replies')
        tooltip = plugins.PointHTMLTooltip(freq_plot[0],voffset=10, hoffset=10)
        plugins.connect(fig, tooltip)
        return fig
        
    def generate_sentiment_plot(self,data_with_sentiment):
        senti=[i['sentiment'] for i in data_with_sentiment]
        senti_df=pd.DataFrame(senti,columns=["Sentiment"])
        senti_counts=senti_df["Sentiment"].value_counts()
        fig, ax = plt.subplots()
        senti_plot=ax.bar(senti_counts.index, senti_counts.values)
        ax.set_xlabel('Sentiment',size=12)
        #ax.set_ylabel('%age of Tweet Replies',size=12)
        ax.set_title('Sentiment Analysis of Tweet Replies', size=17)
        plt.xticks(senti_counts.index)
        
        tooltip = plugins.PointHTMLTooltip(senti_plot[0],voffset=10, hoffset=10)
        plugins.connect(fig, tooltip)
        return fig
    
    def get_sentiment_plot(self):
        translated_tweets=self.translate_data(self.data)
        tweets_with_sentments=self.analyse_sentiment(translated_tweets)
        senti_graph=self.generate_sentiment_plot(tweets_with_sentments)
        #mygraph="/Users/ankitanand/Box/UB/Fall 2019/IR/Proj1/cooked/graph.html"
        senti_graph_html=mpld3.fig_to_html(senti_graph)
        #senti_graph_html=mpld3.save_html(senti_graph,mygraph)
        return senti_graph_html
    
    def get_top10_word_plot(self):
         translated_tweets=self.translate_data(self.data)
         tweets_with_sentments=self.analyse_sentiment(translated_tweets)
         tokenized_tweets=self.tokenize_tweets(tweets_with_sentments)
         without_stop_words=self.remove_stopwords(tokenized_tweets)
         wrd_list=self.get_top10_words(without_stop_words)
         top10_wrds_graph=self.generate_top10_word_plot(wrd_list)
         #mygraph="/Users/ankitanand/Box/UB/Fall 2019/IR/Proj1/cooked/graph.html"
         #top10_fig_html=mpld3.save_html(fig,mygraph)
         top10_fig_html=mpld3.fig_to_html(top10_wrds_graph)
         return top10_fig_html

"""data_path="/Users/ankitanand/Box/UB/Fall 2019/IR/Proj1/cooked/"
my_docs = open(data_path+'cooked_india_18.json')
data = json.load(my_docs)
senti=SentimentAnalyzer(data)
senti_plt=senti.get_sentiment_plot()
freq_plt=senti.get_top10_word_plot()"""

